<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>The Apache Crail (Incubating) Project: Documentation</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link href="https://animeshtrivedi.github.io/crail-website/css/bootstrap.min.css" rel="stylesheet">
        <link href="https://animeshtrivedi.github.io/crail-website/css/group.css" rel="stylesheet">
        <link rel="alternate" type="application/atom+xml" title="Atom"
            href="https://animeshtrivedi.github.io/crail-website/blog/blog.xml">
        
        <meta property="og:image" content="https://animeshtrivedi.github.io/crail-website/img/blog/preview/documentation-summary.png" />
        <meta property="og:image:secure_url" content="https://animeshtrivedi.github.io/crail-website/img/blog/preview/documentation-summary.png" />
    </head>

    <body>
        <div class="container">
          <div class="header">
            <ul class="nav nav-pills pull-right">
              
              
                
                <li >
                  <a href="https://animeshtrivedi.github.io/crail-website/">
                    Home
                  </a>
                </li>
              
                
                <li >
                  <a href="https://animeshtrivedi.github.io/crail-website/overview/">
                    Overview
                  </a>
                </li>
              
                
                <li >
                  <a href="https://animeshtrivedi.github.io/crail-website/blog/">
                    Blog
                  </a>
                </li>
              
                
                <li >
                  <a href="https://animeshtrivedi.github.io/crail-website/community/">
                    Community
                  </a>
                </li>
              
                
                <li class="active">
                  <a href="https://animeshtrivedi.github.io/crail-website/documentation/">
                    Documentation
                  </a>
                </li>
              
            </ul>
            <a href="https://animeshtrivedi.github.io/crail-website/">
                <img src="https://animeshtrivedi.github.io/crail-website/img/crail_logo.png"
                    srcset="https://animeshtrivedi.github.io/crail-website/img/crail_logo.png"
                    alt="Crail" id="logo">
            </a>
          </div>

          
          
          <h2>Documentation</h2>   
          

          <p>The Crail I/O stack consists of a set of components. Typically only a subset of the components are required for a particular use case (e.g., Spark, Hadoop, Hive, etc.) or hardware setup (e.g., RDMA, TCP, Flash, etc.). Here is a list of the components together with their GitHub repository.</p>

<ul>
  <li><a href="https://animeshtrivedi.github.io/crail-website/community/">Crail Store</a>: The backbone for all I/O operations across distributed storage resource. Includes both the RDMA/DRAM and the NVMf/Flash storage tier.</li>
  <li><a href="https://github.com/zrlio/crail-blkdev">Crail-Blkdev</a>: A Crail storage tier for shared volume storage.</li>
  <li><a href="https://github.com/zrlio/crail-netty">Crail-Netty</a>: A Crail TCP/DRAM storage tier built on top of Netty.</li>
  <li><a href="https://github.com/zrlio/crail-spark-io">Crail-Spark-IO</a>: A module including Crail-based Shuffle and Broadcast plugins for Spark.</li>
  <li><a href="https://github.com/zrlio/crail-terasort">Crail-Spark-TeraSort</a>: Currently only the sorting benchmark is available.</li>
</ul>

<p>We currently do not provide binary releases. This page describes how to build the Crail I/O stack from source, and how to configure and deploy it.</p>

<h2 id="crail">Building Crail Store</h2>

<p>Building the source requires <a href="http://maven.apache.org/">Apache Maven</a> and Java version 8 or higher.
To build Crail execute the following steps:</p>

<ol>
  <li>Obtain a copy of <a href="https://animeshtrivedi.github.io/crail-website/community/">Crail Store</a></li>
  <li>Make sure your local maven repo contains <a href="https://github.com/zrlio/disni">DiSNI</a>, if not build DiSNI from Github</li>
  <li>Make sure your local maven repo contains <a href="https://github.com/zrlio/darpc">DaRPC</a>, if not build DaRPC from Github</li>
  <li>Run: mvn -DskipTests install</li>
  <li>Copy tarball to the cluster and unpack it using tar xvfz crail-1.0-bin.tar.gz</li>
</ol>

<p>Note: later, when deploying Crail, make sure libdisni.so is part of your LD_LIBRARY_PATH. The easiest way to make it work is to copy libdisni.so into crail-1.0/lib</p>

<h3 id="configuration">Configuration</h3>

<p>To configure Crail use crail-site.conf.template as a basis and modify it to match your environment.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd crail-1.0/conf
mv crail-site.conf.template crail-site.conf
</code></pre></div></div>

<p>There are a general file system properties and specific properties for the different storage tiers. A typical configuration for the general file system section may look as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>crail.namenode.address                crail://namenode:9060
crail.storage.types                   org.apache.crail.storage.rdma.RdmaStorageTier
crail.cachepath                       /memory/cache
crail.cachelimit                      12884901888
crail.blocksize                       1048576
crail.buffersize                      1048576
</code></pre></div></div>

<p>In this configuration the namenode is configured to run using port 9060 on host ‘namenode’, which must be a valid host in the cluster. We further configure a single storage tier, in this case the RDMA-based DRAM tier. Cachepath points to a directory that is used by the file system to allocate memory for the client cache. Up to cachelimit size, all the memory that is used by Crail will be allocated via mmap from this location. Ideally, the directory specified in cachepath points to a hugetlbfs mountpoint. Aside from the general properties, each storage tier needs to be configured separately.</p>

<h4 id="rdmadram-storage-tier">RDMA/DRAM Storage Tier</h4>

<p>For the RDMA/DRAM tier we need to specify the interface that should be used by the storage nodes.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>crail.storage.rdma.interface          eth0
</code></pre></div></div>

<p>The datapath property specifies a path from which the storage nodes will allocate blocks of memory via mmap. Again, that path best points to a hugetlbfs mountpoint.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>crail.storage.rdma.datapath           /memory/data
</code></pre></div></div>

<p>You want to specify how much DRAM each datanode should donate into the file system pool using the <code class="highlighter-rouge">storagelimit</code> property. DRAM is allocated in chunks of <code class="highlighter-rouge">allocationsize</code>, which needs to be a multiple of <code class="highlighter-rouge">crail.blocksize</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>crail.storage.rdma.allocationsize     1073741824
crail.storage.rdma.storagelimit       75161927680
</code></pre></div></div>

<p>Crail supports optimized local operations via memcpy (instead of RDMA) in case a given file operation is backed by a local storage node. The indexpath specifies where Crail will store the necessary metadata that make these optimizations possible. Important: the indexpath must NOT point to a hugetlbfs mountpoint because index files will be updated which not possible in hugetlbfs.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>crail.storage.rdma.localmap           true
crail.storage.rdma.indexpath          /index
</code></pre></div></div>

<h4 id="nvmfflash-storage-tier">NVMf/Flash Storage Tier</h4>

<p>Crail is a multi-tiered storage system. Additinoal tiers can be enabled by adding them to the configuration as follows.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>crail.storage.types                  org.apache.crail.storage.rdma.RdmaStorageTier,org.apache.crail.storage.nvmf.NvmfStorageTier
</code></pre></div></div>

<p>For the NVMf storage tier we need to configure the server IP that is used when listening for new connections. We also need to configure the PCI address of the flash device we want to use, as well as the huge page mount point to be used for allocating memory.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>crail.storage.nvmf.bindip		10.40.0.XX
crail.storage.nvmf.pcieaddr		0000:11:00.0
crail.storage.nvmf.hugedir		/dev/hugepages
crail.storage.nvmf.socketmem		512,512
</code></pre></div></div>

<h3 id="deployment">Deployment</h3>

<p>For all deployments, make sure you define CRAIL_HOME on each machine to point to the top level Crail directory.</p>

<h4 id="starting-crail-manually">Starting Crail manually</h4>

<p>The simplest way to run Crail is to start it manually on just a handful nodes. You will need to start the Crail namenode, plus at least one datanode. To start the namenode execute the following command on the host that is configured to be the namenode:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd crail-1.0/
./bin/crail namenode
</code></pre></div></div>

<p>To start a datanode run the following command on a host in the cluster (ideally this is a different physical machine than the one running the namenode):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/crail datanode
</code></pre></div></div>

<p>Now you should have a small deployment up with just one datanode. In this case the datanode is of type RDMA/DRAM, which is the default datnode. If you want to start a different storage tier you can do so by passing a specific datanode class as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/crail datanode -t org.apache.crail.storage.nvmf.NvmfStorageTier
</code></pre></div></div>

<p>This would start the shared storage datanode. Note that configuration in crail-site.conf needs to have the specific properties set of this type of datanode, in order for this to work.</p>

<h4 id="larger-deployments">Larger deployments</h4>

<p>To run larger deployments start Crail using</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/start-crail.sh
</code></pre></div></div>

<p>Similarly, Crail can be stopped by using</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/stop-crail.sh
</code></pre></div></div>

<p>For this to work include the list of machines to start datanodes in conf/slaves. You can start multiple datanode of different types on the same host as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>host02-ib
host02-ib -t org.apache.crail.storage.nvmf.NvmfStorageTier
host03-ib
</code></pre></div></div>

<p>In this example, we are configuring a Crail cluster with 2 physical hosts but 3 datanodes and two different storage tiers.</p>

<h3 id="crail-shell">Crail Shell</h3>

<p>Crail provides an contains an HDFS adaptor, thus, you can interact with Crail using the HDFS shell:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/crail fs
</code></pre></div></div>

<p>Crail, however, does not implement the full HDFS shell functionality. The basic commands to copy file to/from Crail, or to move and delete files, will work.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/crail fs -mkdir /test
./bin/crail fs -ls /
./bin/crail fs -copyFromLocal &lt;path-to-local-file&gt; /test
./bin/crail fs -cat /test/&lt;file-name&gt;
</code></pre></div></div>

<p>For the Crail shell to work properly, the HDFS configuration in crail-1.0/conf/core-site.xml needs to be configured accordingly:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;configuration&gt;
  &lt;property&gt;
   &lt;name&gt;fs.crail.impl&lt;/name&gt;
   &lt;value&gt;org.apache.crail.hdfs.CrailHadoopFileSystem&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;crail://namenode:9060&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;fs.AbstractFileSystem.crail.impl&lt;/name&gt;
    &lt;value&gt;org.apache.crail.hdfs.CrailHDFS&lt;/value&gt;
  &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre></div></div>

<p>Note that the Crail HDFS interface currently cannot provide the full performance of Crail due to limitations of the HDFS API. In particular, the HDFS <code class="highlighter-rouge">FSDataOutputStream</code> API only support heap-based <code class="highlighter-rouge">byte[]</code> arrays which requires a data copy. Moreover, HDFS operations are synchronous preventing efficient pipelining of operations. Instead, applications that seek the best performance should use the Crail interface directly, as shown next.</p>

<h3 id="programming-against-crail">Programming against Crail</h3>

<p>The best way to program against Crail is to use Maven. Make sure you have the Crail dependency specified in your application pom.xml file:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;dependency&gt;
  &lt;groupId&gt;org.apache.crail&lt;/groupId&gt;
  &lt;artifactId&gt;crail-client&lt;/artifactId&gt;
  &lt;version&gt;1.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre></div></div>

<p>Then, create a Crail file system instance as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CrailConfiguration conf = new CrailConfiguration();
CrailFS fs = CrailFS.newInstance(conf);
</code></pre></div></div>

<p>Make sure the crail-1.0/conf directory is part of the classpath.</p>

<p>The simplest way to create a file in Crail is as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CrailFile file = fs.create(filename, CrailNodeType.DATAFILE, CrailStorageClass.DEFAULT, CrailLocationClass.DEFAULT).get().syncDir();
</code></pre></div></div>

<p>Aside from the actual filename, the ‘create()’ call takes as input the storage and location classes which are preferences for the storage tier and physical location that this file should be created in. Crail tries to satisfy these preferences later when the file is written. In the example we do not request any particular storage or location affinity.</p>

<p>The ‘create()’ call is non-blocking, calling ‘get()’ on the returning future object awaits the completion of the call. At that time, the file has been created, but its directory entry may not be visible. Therefore, the file may not yet show up in a file enumeration of the given parent directory. Calling ‘syncDir()’ waits to for the directory entry to be completed. Both the ‘get()’ and the ‘syncDir()’ operation can be deffered to a later time at which they may become non-blocking operations.</p>

<p>Once the file is created, a file stream can be obtained for writing:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CrailBufferedOutputStream outstream = file.getBufferedOutputStream(1024);	
</code></pre></div></div>

<p>Here, we create a buffered stream so that we can pass heap byte arrays as well. We could also create a non-buffered stream using</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CrailOutputStream outstream = file.getDirectOutputStream(1024);
</code></pre></div></div>

<p>In both cases, we pass a write hint (1024 in the example) that indicates to Crail how much data we are intending to write. This allows Crail to optimize metadatanode lookups. Crail never prefetches data, but it may fetch the metadata of the very next operation concurrently with the current data operation if the write hint allows to do so.</p>

<p>Once the stream has been obtained, there exist various ways to write a file. The code snippet below shows the use of the asynchronous interface:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ByteBuffer dataBuf = fs.allocateBuffer();
Future&lt;DataResult&gt; future = outputStream.write(dataBuf);
...
future.get();
</code></pre></div></div>

<p>Reading files works very similar to writing. There exist various examples in org.apache.crail.tools.CrailBenchmark.</p>

<h3 id="storage-tiers">Storage Tiers</h3>

<p>Crail ships with the RDMA/DRAM storage tier. Currently there are two additional storage tiers available in separate repos:</p>

<ul>
  <li><a href="https://github.com/zrlio/crail-blkdev">Crail-Blkdev</a>  is a storage tier integrating shared volume block devices such as disaggregated flash.</li>
  <li><a href="https://github.com/zrlio/crail-netty">Crail-Netty</a> is a DRAM storage tier for Crail that uses TCP, you can use it to run Crail on non-RDMA hardware. Follow the instructions in these repos to build, deploy and use these storage tiers in your Crail environmnet.</li>
</ul>

<h3 id="benchmarks">Benchmarks</h3>

<p>Crail provides a set of benchmark tools to measure the performance. Type</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/crail iobench
</code></pre></div></div>

<p>to get an overview of the available benchmarks. For instance, to benchmark the sequential write performance, type</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/crail iobench -t write -s 1048576 -k 102400 -f /tmp.dat
</code></pre></div></div>

<p>This will create a file of size 100G, written sequentially in a sequence of 1MB operations.</p>

<p>To read a file sequentially, type</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/crail iobench -t read -s 1048576 -k 102400 -f /tmp.dat
</code></pre></div></div>

<p>This command issues 102400 read operations of 1MB each.</p>

<p>The tool also contains benchmarks to read files randomly, or to measure the performance of opening files, etc.</p>

<h2 id="spark">Building Crail Spark Modules</h2>

<p>Building the source requires <a href="http://maven.apache.org/">Apache Maven</a> and Java version 8 or higher.
To build Crail execute the following steps:</p>

<ol>
  <li>Obtain a copy of <a href="https://github.com/zrlio/crail-spark-io">Crail-Spark-IO</a> from Github</li>
  <li>Make sure your local maven repo contains crail store jars, if not build Crail from the <a href="https://animeshtrivedi.github.io/crail-website/community/">source</a></li>
  <li>Run: mvn -DskipTests install</li>
  <li>Add crail-spark-1.0.jar as well as its Crail dependencies to the Spark extra class path, both for the driver and the executors</li>
</ol>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark.driver.extraClassPath     $CRAIL_HOME/jars/*:&lt;path&gt;/crail-spark.jar:.
spark.executor.extraClassPath   $CRAIL_HOME/jars/*:&lt;path&gt;/crail-spark.jar:.
</code></pre></div></div>

<h3 id="configuration-1">Configuration</h3>

<p>To configure the crail shuffle plugin included in spark-io add the following line to spark-defaults.conf</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark.shuffle.manager		org.apache.spark.shuffle.crail.CrailShuffleManager
</code></pre></div></div>
<p>Since spark version 2.0.0, broadcast is no longer an exchangeable plugin, unfortunately. To use the crail broadcast plugin in Spark it has to be manually added to Spark’s BroadcastManager.scala.</p>

<h3 id="running">Running</h3>

<p>For the Crail shuffler to perform best, applications are encouraged to provide an implementation of the <code class="highlighter-rouge">CrailShuffleSerializer</code> interface, as well as an implementation of the <code class="highlighter-rouge">CrailShuffleSorter</code> interface. Defining its own custom serializer and sorter for the shuffle phase not only allows the application to serialize and sort faster, but allows applications to directly leverage the functionality provided by the Crail input/output streams such as zero-copy or asynchronous operations. Custom serializer and sorter can be specified in spark-defaults.xml. For instance, <a href="https://github.com/zrlio/crail-terasort">crail-terasort</a> defines the shuffle serializer and sorter as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark.crail.shuffle.sorter     com.ibm.crail.terasort.sorter.CrailShuffleNativeRadixSorter
spark.crail.shuffle.serializer com.ibm.crail.terasort.serializer.F22Serializer
</code></pre></div></div>



        <br>
	<br> 
          <div class="footer">
            <p>Apache Crail is an effort undergoing <a href="https://incubator.apache.org/">incubation</a> at <a href="https://www.apache.org/">The Apache Software Foundation (ASF)</a>, sponsored by the Apache Incubator PMC. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
            </p>
          </div>

        </div> <!-- /container -->

        <!-- Support retina images. -->
        <script type="text/javascript"
            src="https://animeshtrivedi.github.io/crail-website/js/srcset-polyfill.js"></script>
    </body>
</html>
